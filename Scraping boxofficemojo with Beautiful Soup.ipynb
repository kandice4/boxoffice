{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_requests(main, pages, f_prefix='request', adj='', start=1, stop=None):\n",
    "    \"\"\"\n",
    "    Return: Save requests to working directory subdirectory requests/ with filename\n",
    "    equal to the f_prefix string followed by index starting at 1.\n",
    "    Arguments:\n",
    "    main: homepage url of requests as string\n",
    "    pages: list of subpages as strings\n",
    "    adj: extension for adjusted url\n",
    "    start: start index\n",
    "    stop: stop index\n",
    "    \"\"\"\n",
    "    for i, page in enumerate(pages[start-1:stop],start=start):\n",
    "        save_request(main + page + adj, f'{f_prefix}{i}')\n",
    "\n",
    "def save_request(url, filename):\n",
    "    response = requests.get(url)\n",
    "    with open(f'requests/{filename}', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def make_soup(filename):\n",
    "    with open(f'requests/{filename}', 'rb') as f:\n",
    "        return BeautifulSoup(f, 'lxml')\n",
    "\n",
    "def get_soups(f_prefix, n):\n",
    "    soups = []\n",
    "    for i in range(1, n+1):\n",
    "        soups.append(make_soup(f'{f_prefix}{i}'))\n",
    "    return soups\n",
    "\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    return soup\n",
    "\n",
    "def get_links(soup, page):\n",
    "    links = {a['href'] for a in soup.find_all('a')\\\n",
    "            if a['href'][:len(page)] == page}\n",
    "    return links\n",
    "\n",
    "def get_AZ(main, page):\n",
    "    num_page = '/movies/alphabetical.htm?letter=NUM&p=.htm'\n",
    "    links = get_links(get_soup(main + page), page)\n",
    "    AZ = set()\n",
    "    for link in links:\n",
    "        soup = get_soup(main + link)\n",
    "        AZ = AZ.union(get_links(soup, page))\n",
    "    AZ.remove(num_page)\n",
    "    return [num_page] + sorted(AZ)\n",
    "\n",
    "def get_tables_movies(AZ_soups):\n",
    "    tables = [['Link','Title', 'Studio', 'Total Gross', 'Total Theaters', \\\n",
    "              'Opening', 'Opening Theaters', 'Open']]\n",
    "    movies = []\n",
    "    for soup in AZ_soups:\n",
    "        links = ['Link']+[tr.find(\"a\")['href'] for tr \\\n",
    "                in soup.find_all('table')[3].find_all('tr')[1:]]\n",
    "        contents = [[td.get_text(separator=' ') for td in tr.find_all('td')] \\\n",
    "                    for tr in soup.find_all('table')[3].find_all('tr')]\n",
    "        for link, content in list(zip(links,contents))[1:]:\n",
    "            if link not in movies:\n",
    "                tables.append([link] + content)\n",
    "                movies.append(link)\n",
    "    return tables, movies\n",
    "\n",
    "def get_title_year(soup):\n",
    "    string = soup.title.text.partition(\" - Box Office Mojo\")[0]\n",
    "    if string[-1] == \")\":\n",
    "        title = string[:-7]\n",
    "        year = string[-5:-1]\n",
    "    else:\n",
    "        title = string.strip()\n",
    "        year = None\n",
    "    return title, year\n",
    "\n",
    "def get_series(soup):\n",
    "    series = soup.find(text=re.compile('Series:'))\n",
    "    if series:\n",
    "        series = series.partition('Series: ')[-1]\n",
    "    return series\n",
    "\n",
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "\n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj:\n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.next_sibling\n",
    "    next_element = obj.next_element\n",
    "    if next_sibling:\n",
    "        return next_sibling.get_text(separator=', ')\n",
    "    elif next_element:\n",
    "        try:\n",
    "            return obj.next_element.get_text(separator=', ')\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                return obj.next_element.next_element.get_text(separator=', ')\n",
    "            except:\n",
    "                return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_movie_info(movies, soups, adj=False, header=False):\n",
    "    if not header:\n",
    "        movie_info = []\n",
    "    elif not adj:\n",
    "        movie_info = [['page', 'title', 'year', 'opening', 'domestic', \\\n",
    "                    'budget', 'series', 'distr', 'rating', 'release', 'genre',\\\n",
    "                    'runtime', 'directors', 'writers', 'actors', 'producers']]\n",
    "    else:\n",
    "        movie_info = [['page', 'title', 'year', 'opening_adj', 'domestic_adj', \\\n",
    "                    'budget_adj']]\n",
    "    for page, soup in zip(movies, soups):\n",
    "        title, year = get_title_year(soup)\n",
    "        opening = get_movie_value(soup, 'Weekend:')\n",
    "        domestic = get_movie_value(soup,'Domestic Total')\n",
    "        budget = get_movie_value(soup, 'Budget:')\n",
    "        if not adj:\n",
    "            series = get_series(soup)\n",
    "            distr = get_movie_value(soup, 'Distributor')\n",
    "            rating = get_movie_value(soup,'MPAA Rating')\n",
    "            release = get_movie_value(soup,'Release Date')\n",
    "            genre = get_movie_value(soup, 'Genre:')\n",
    "            runtime = get_movie_value(soup,'Runtime')\n",
    "            directors = get_movie_value(soup, 'Director')\n",
    "            writers = get_movie_value(soup, 'Writer')\n",
    "            actors = get_movie_value(soup, 'Actor')\n",
    "            producers = get_movie_value(soup, 'Producer')\n",
    "            movie_info.append([page, title, year, opening, domestic, budget, \\\n",
    "                                series, distr, rating, release, genre, runtime,\\\n",
    "                                directors, writers, actors, producers])\n",
    "        else:\n",
    "            movie_info.append([page, title, year, opening, domestic, budget])\n",
    "    return movie_info\n",
    "\n",
    "def make_pickles(objs):\n",
    "    for filename, obj in objs:\n",
    "        with open(filename, \"wb\") as picklefile:\n",
    "            pickle.dump(obj, picklefile)\n",
    "\n",
    "def get_pickles(pkls):\n",
    "    if len(pkls) == 1:\n",
    "        with open(pkls[0], \"rb\") as picklefile:\n",
    "            objs = pickle.load(picklefile)\n",
    "    else:\n",
    "        objs = []\n",
    "        for filename in pkls:\n",
    "            with open(filename, \"rb\") as picklefile:\n",
    "                objs.append(pickle.load(picklefile))\n",
    "    return objs\n",
    "\n",
    "import dateutil.parser\n",
    "\n",
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date\n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return int(moneystring)\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main = 'http://www.boxofficemojo.com'\n",
    "page = '/movies/alphabetical.htm'\n",
    "adj = '&adjust_yr=2017&p=.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AZ = get_AZ(main, page)\n",
    "#save_requests(main, AZ, 'AZ')\n",
    "#AZ_soups = get_soups('AZ', len(AZ))\n",
    "AZ_tables, movies = get_tables_movies(AZ_soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('AZ.pkl', AZ), ('AZ_tables.pkl', AZ_tables), ('movies.pkl',movies)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AZ, AZ_tables, movies = get_pickles(['AZ.pkl', 'AZ_tables.pkl', 'movies.pkl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 17557\n",
    "stop = None\n",
    "save_requests(main, movies, 'movies', '', start, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 17557\n",
    "save_requests(main, movies, 'movieadj', adj, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_soups = get_soups('movies', len(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieadj_soups = get_soups('movieadj', len(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main = 'http://www.the-numbers.com/movie/budgets/all/'\n",
    "pages = [str(100*x+1) for x in range(55)]\n",
    "\n",
    "start = 1\n",
    "save_requests(main, pages, 'numbers', '', start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "movie_info = get_movie_info(movies, movies_soups, adj=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('movie_info.pkl', movie_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "movieadj_info = get_movie_info(movies, movieadj_soups, adj=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('movieadj_info.pkl', movieadj_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame(np.array(movie_info[1:]), columns=movie_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieadj_df = pd.DataFrame(np.array(movieadj_info[1:]), columns=movieadj_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('movie_df.pkl',movie_df),('movieadj_df.pkl',movieadj_df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = movie_df.merge(movieadj_df, on=['page', 'title', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('df.pkl',df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_AZ = pd.DataFrame(AZ_tables[1:], columns=AZ_tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('df_AZ.pkl',df_AZ)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers_soups = get_soups('numbers', 55 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tables_budgets(numbers_soups):\n",
    "    tables = [['Release Date', 'Movie', 'Production Budget', 'Domestic Gross', 'Worldwide Gross']]  \n",
    "    for soup in numbers_soups:\n",
    "        contents = [[td.get_text().replace('Ã¢\\x80\\x99','\\'') for td in tr.find_all('td')] \\\n",
    "                    for i, tr in enumerate(soup.find('table').find_all('tr')) if i%2!=0]\n",
    "        for content in contents:\n",
    "            tables.append(content[1:])\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers_tables = get_tables_budgets(numbers_soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_numbers = pd.DataFrame(numbers_tables[1:], columns=numbers_tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Production Budget</th>\n",
       "      <th>Domestic Gross</th>\n",
       "      <th>Worldwide Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>12/31/2007</td>\n",
       "      <td>A Dog's Breakfast</td>\n",
       "      <td>$120,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>12/31/2007</td>\n",
       "      <td>A Dog's Breakfast</td>\n",
       "      <td>$120,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Release Date              Movie Production Budget Domestic Gross  \\\n",
       "5308   12/31/2007  A Dog's Breakfast          $120,000             $0   \n",
       "5309   12/31/2007  A Dog's Breakfast          $120,000             $0   \n",
       "\n",
       "     Worldwide Gross  \n",
       "5308              $0  \n",
       "5309              $0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numbers[df_numbers.duplicated(keep=False)].sort_values(by='Movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_numbers.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pickles([('df_numbers.pkl', df_numbers), ('numbers_tables.pkl', numbers_tables)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
